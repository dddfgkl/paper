# An Attentive Survey of Attention Models  
一篇关于attention的survey  
[LINK:] https://arxiv.org/pdf/1904.02874.pdf  

----  

## 一、Attention的分类  

### 1、Number of sequences   
#### (1) Distinctive   

#### (2) Co-attention      
- Hierarchical question-image co-attention for visual question answering  
co-attention应用在VQA领域的文章   
[LINK:] https://arxiv.org/pdf/1606.00061.pdf  


#### (3) self-attention  


----  

### 2、Number of abstraction levels  
#### (1) single-level    

#### (2) multi-level    
- Hierarchical Attention Networks for Document Classification  
多尺度attention在文本分类任务上的应用  
[LINK:] https://www.cs.cmu.edu/~./hovy/papers/16HLT-hierarchical-attention-networks.pdf  



---- 

### 3、Number of positions
Soft & Hard & Local & Global  

---- 


### 4、Number of representations  

 

----

## 二、与Attention结合的模型  

